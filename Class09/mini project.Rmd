---
title: "Mini project:Analysis Using Unsupervised Learning Techniques"
author: "Alicia Pacheco"
date: "October 30, 2018"
output: github_document
---

The goal of this hands-on session is to to explore a complete analysis using the unsupervised learning techniques covered in the last class. Extend what has been learned by combining PCA as a preprocessing step to clustering using data that consist of measurements of cell nuclei of human breast masses. 


The data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#Section 1
##Preparing the data

Import the data 

```{r}
url <- "https://bioboot.github.io/bimm143_W18/class-material/WisconsinCancer.csv"

#Input the data and store as wisc.df
wisc.df <- read.csv(url)
head(wisc.df)
```

Converting the features of the data

```{r}

#Making a new matrix from colums 3 to 32 in wisc.df  
wisc.data <- as.matrix(wisc.df[3:32] )

id<-colnames(wisc.data)

#Setting the row names of wisc.data  
row.names(wisc.data) <- wisc.df$id

```


Explortory data analysis

```{r}
#How many patients?
nrow(wisc.df)

```



```{r}
#How many of the observations have malignant diagnosis?
diagnosis<-as.numeric(wisc.df$diagnosis=="M")
sum(diagnosis)

```
```{r}
#Looking for patterns: "_means"

x<-length(grep("_mean",colnames(wisc.data)))

x
```




#Section 2
##Performing PCA 


```{r}

#Checking column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)

```


```{r}
#Perform PCA on wisc.data 
wisc.pr <- prcomp(wisc.data,scale=TRUE)
summary(wisc.pr)


```

```{r}

#attributes
attributes(wisc.pr)
dim(wisc.pr$x)

```


##Interpreting PCA results

Scatter plot observations by components 1 and 2
```{r}

plot(wisc.pr$x[,1],wisc.pr$x[,2],col=diagnosis+1,xlab = "PC1", ylab = "PC2")

    
```

Scatter plot observations by components 1 and 3
```{r}

plot(wisc.pr$x[, c(1, 3)], col = (diagnosis + 1), 
     xlab = "PC1", ylab = "PC3")

```

Because principal component 2 explains more variance in the original data than principal component 3, the first plot has a cleaner cut separating the two subgroups. 


Creating a plot of cumulative proportion of variance

```{r}
pr.var<-wisc.pr$sdev^2

# Variance explained by each principal component: pve
pve <-  pr.var/sum(pr.var)

# Plot cumulative proportion of variance explained
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

Alternative data plot

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )

```



#Section 3
#Hierarchical clustering of case data

The data is scaled. The distance between all pairs of observations are computed, 

```{r}
#The data is scaled
data.scaled<-scale(wisc.data)

#Distances(Elucidean) between all pairs of observation in the new scaled data are calculated
data.dist<-dist(data.scaled)

#Creating a hierarchical clustering model using complete linkage
wisc.hclust<-hclust(data.dist,"complete")

```
Results of hierarcical clustering
```{r}
plot(wisc.hclust)
wisc.hclust.clusters<-cutree(wisc.hclust,k=4)
table(wisc.hclust.clusters)
table(wisc.hclust.clusters,diagnosis)
```

Using the distance along the first 7 PCs for clustering

```{r}
#Using the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
#wisc.pr$x[ ,1:7]
dis.pr<-dist(wisc.pr$x[ ,1:7])
wisc.pr.hclust <- hclust(dis.pr, method="complete")

wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
table(wisc.hclust.clusters)
table(wisc.hclust.clusters,diagnosis)

```

## Bonus: Predicting modeling with PCA Components


```{r}

## Predicting Malignancy Of New samples
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
plot(wisc.pr$x[,1:2], col=diagnosis+1)
points(npc[,1], npc[,2], col="blue", pch=16, cex=2)


```
Patient near red=bad, patient near black=good

